{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning:  Predictive Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of data mining is to tease out characteristic behaviors and interesting subsets and interactions.  Random modeling (Monte Carlo techniques) allows you to attempt this characterization on an unbiased sample of the overall data set.\n",
    "\n",
    "A [Markov model](https://en.wikipedia.org/wiki/Markov_model) simulates a chain of states in which each future state can be derived from the current state (rather than the full history).  Future states are randomly determined based on information about the current state (called a _transition function_).\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Markovkate_01.svg/640px-Markovkate_01.svg.png)\n",
    "\n",
    "Markov modeling is frequently used to represent time series data in which the next state is dependent on the current state.  (Many systems which are partially unpredicatable, like weather, behave this way.  If you were to predict that the temperature in ten minutes is about what it is now, you'd frequently be correct.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = (10,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plain vanilla Markov modeling assumes that you know everything about the system, that is, all of the transition likelihoods.  Much of the time you do not, so you must build a _hidden Markov model_ (HMM).  This is useful for speech recognition, weather modeling, and many other systems.\n",
    "\n",
    "The [hidden Markov model (HMM)](https://en.wikipedia.org/wiki/Hidden_Markov_model) thus makes observation from hidden states.  In essence, we are attempting to infer from outcomes what the likely inputs were, a sort of zeroth-order Bayesian inference.  The goal of the hidden Markov model may be stated thus:\n",
    "\n",
    "> The parameter learning task in HMMs is to find, given an output sequence or a set of such sequences, the best set of state transition and emission probabilities.\n",
    "\n",
    "More broadly, this goal breaks down into [three different problem approaches](http://scikit-learn.sourceforge.net/stable/modules/hmm.html):\n",
    "\n",
    "1.  Given the model parameters and observed data, estimate the optimal sequence of hidden states.\n",
    "2.  Given the model parameters and observed data, calculate the likelihood of the data.\n",
    "3.  Given just the observed data, estimate the model parameters.\n",
    "\n",
    "We will adopt the following terminology:\n",
    "\n",
    "1.  **observations**:  observed data (revealed samples)\n",
    "\n",
    "2.  **hidden states**:  unobserved states to generate observations\n",
    "\n",
    "3.  **transition probability matrix**:  a probabilistic matrix to simulate a\n",
    "sequence of hidden states\n",
    "\n",
    "4.  **emission probability matrix**:  a probabilistic matrix to generate\n",
    "observations from hidden states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:  Generating a Hidden Markov Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the weather tomorrow is only dependent on the weather today.  The next day will rain with a probability of 0.9 (with 0.1 for not rain) if the current day is rainy.  If the current day is not rainy, there is a probability of 0.4 for the next day to rain (0.6 for the next day to not rain). On a rainy day, the probability of swimming, basketball and hiking is 0.8, 0.1 and 0.1, respectively. On a non-rainy day, the corresponding probability of these sports are 0.2, 0.3 and 0.5, respectively.\n",
    "\n",
    "![](./rainy.png)\n",
    "\n",
    "Generate the hidden Markov process as follows:\n",
    "\n",
    "1.  Denote \"rainy\" as 1 and \"sunny\" as 2;\n",
    "2.  Denote \"swimming\", \"basketball\" and \"hiking\" as 1, 2, and 3.\n",
    "3.  Suppose the first day is rainy (our starting state).\n",
    "\n",
    "The transition matrix looks like:\n",
    "\n",
    "|     |  1  |  2  |\n",
    "| --- | --- | --- |\n",
    "|  1  | 0.9 | 0.1 |\n",
    "|  2  | 0.4 | 0.6 |\n",
    "\n",
    "(Note what order the rows and columns read into each other.)\n",
    "\n",
    "The emission matrix looks like:\n",
    "\n",
    "|     |  1  |  2  |  3  |\n",
    "| --- | --- | --- | --- |\n",
    "|  1  | 0.8 | 0.1 | 0.1 |\n",
    "|  2  | 0.2 | 0.3 | 0.5 |\n",
    "\n",
    "We observe only the behaviors, or *observations* (the states $1--3$ given by the emission matrix) and wish to infer the weather *state* $\\in \\{ 1,2 \\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In code, we can represent this state of affairs as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition = np.array( [ [ 0.9,0.1 ],[ 0.4,0.6 ] ] )\n",
    "emission   = np.array( [ [ 0.8,0.1,0.1 ],[ 0.2,0.3,0.5 ] ] )\n",
    "\n",
    "hiddenStateList = np.array( [ 1,2 ] );      # all possible states\n",
    "observationList = np.array( [ 1,2,3 ] );    # all possible observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HMM will be built progressively, step by step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "states = np.zeros( ( n, ),dtype=np.int )\n",
    "obs    = np.zeros( ( n, ),dtype=np.int )\n",
    "\n",
    "states[ 0 ] = 2     # starting state (hidden from model)\n",
    "probVector = emission[ hiddenStateList == states[ 0 ] ]\n",
    "\n",
    "id = ( np.cumsum( probVector ) >= npr.rand() ).tolist().index( True )\n",
    "obs[ 0 ] = observationList[ id ]\n",
    "\n",
    "for i in range( 1,n ):\n",
    "    probVector = transition[ hiddenStateList == states[ i-1 ] ]\n",
    "    id = ( np.cumsum( probVector ) >= npr.rand() ).tolist().index( True )\n",
    "    states[ i ] = hiddenStateList[ id ]\n",
    "\n",
    "    probVector = emission[ hiddenStateList == states[ i ] ]\n",
    "    id = ( np.cumsum( probVector ) >= npr.rand() ).tolist().index( True )\n",
    "    obs[ i ] = observationList[ id ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the observations and inferred states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.step( range( len( states ) ),states )\n",
    "ax.plot( range( len( obs ) ),obs/2+0.5,color='orange',linestyle='',marker='o' )\n",
    "plt.xlabel( 'Time step' )\n",
    "plt.ylabel( 'Observations' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Model Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`hmmlearn`](http://hmmlearn.readthedocs.io/en/latest/) (formerly `scikit-learn.hmm`) includes a number of tools to automatically generate the HMM process:\n",
    "\n",
    "-   [`GaussianHMM`](http://hmmlearn.readthedocs.io/en/latest/api.html#hmmlearn.hmm.GaussianHMM) Hidden Markov Model with Gaussian emissions.\n",
    "-   [`GMMHMM`](http://hmmlearn.readthedocs.io/en/latest/api.html#hmmlearn.hmm.GMMHMM)\tHidden Markov Model with Gaussian mixture emissions.\n",
    "- [`MultinomialHMM`](http://hmmlearn.readthedocs.io/en/latest/api.html#hmmlearn.hmm.MultinomialHMM) Hidden Markov Model with multinomial (discrete) emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hmmlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:  Generating a HMM Process with `hmmlearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example implementation of the rainy/sunny problem could look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition = np.array( [ [ 0.9,0.1 ],[ 0.4,0.6 ] ] )\n",
    "emission   = np.array( [ [ 0.8,0.1,0.1 ],[ 0.2,0.3,0.5 ] ] )\n",
    "\n",
    "from hmmlearn import hmm\n",
    "model = hmm.MultinomialHMM( n_components=2 )\n",
    "\n",
    "model.startprob_ = np.array( [ 1.0,0.0 ] )  # start as 'rainy'\n",
    "model.transmat_  = transition\n",
    "model.n_features    = 3\n",
    "model.emissionprob_ = emission\n",
    "\n",
    "obs -= 1\n",
    "obs.shape = ( obs.shape[ 0 ],1 )\n",
    "logprob,states_ = model.decode( obs )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the basis changes from $\\{ 1,2,3 \\}$ to $\\{ 0,1,2 \\}$ and that the shape of `obs` must be two-dimensional.\n",
    "\n",
    "Compare the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_ == ( states-1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can train an HMM by calling the fit method. The input is “the list” of the sequence of observed value. Note, since the EM algorithm is a gradient-based optimization method, it will generally get stuck in local optima. You should try to run fit with various initializations and select the highest scored model. The score of the model can be calculated by the score method. The inferred optimal hidden states can be obtained by calling predict method. The predict method can be specified with decoder algorithm. Currently the Viterbi algorithm (viterbi), and maximum a posteriori estimation (map) are supported. This time, the input is a single sequence of observed values. Note, the states in model2 will have a different order than those in the generating model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:  Estimating the Transition and Emission Matrices with `hmmlearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_guess = [ [ 0.5,0.5 ],[ 0.4,0.6 ] ]\n",
    "emission_guess   = [ [ 0.5,0.3,0.2 ],[ 0.3,0.3,0.4 ] ]\n",
    "\n",
    "from hmmlearn import hmm\n",
    "model = hmm.MultinomialHMM( n_components=2 )\n",
    "\n",
    "model.startprob_ = np.array( [ 1.0,0.0 ] )  # start as 'rainy'\n",
    "model.transmat_  = transition_guess\n",
    "model.n_features    = 3\n",
    "model.emissionprob_ = emission_guess\n",
    "\n",
    "states.shape = ( states.shape[ 0 ],1 )\n",
    "model = model.fit( obs )\n",
    "\n",
    "transition_fit = model.transmat_\n",
    "emission_fit   = model.emissionprob_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:  Estimating Hidden States with `hmmlearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we only know the observations of a HMM process.  We would like to know the hidden states, emission matrix and transition states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = 100\n",
    "obs_new = npr.randint( 0,3,( n_obs,1 ) )\n",
    "\n",
    "transition = np.array( [ [ 0.9,0.1 ],[ 0.4,0.6 ] ] )\n",
    "emission   = np.array( [ [ 0.8,0.1,0.1 ],[ 0.2,0.3,0.5 ] ] )\n",
    "\n",
    "from hmmlearn import hmm\n",
    "model = hmm.MultinomialHMM( n_components=2 )\n",
    "\n",
    "model.startprob_ = np.array( [ 1.0,0.0 ] )  # start as 'rainy'\n",
    "model.transmat_  = transition\n",
    "model.n_features    = 3\n",
    "model.emissionprob_ = emission\n",
    "\n",
    "states.shape = ( states.shape[ 0 ],1 )\n",
    "model = model.fit( obs )\n",
    "\n",
    "transition_fit = model.transmat_\n",
    "emission_fit   = model.emissionprob_\n",
    "\n",
    "states_likely = model.predict( obs_new )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   How can we assess this HMM?\n",
    "\n",
    "-   Build a model using the iris dataset to identify which features predict others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These lessons were developed by Erhu Du, Jane Lee, and Neal Davis for Computational Science and Engineering at the University of Illinois.  Development was supported by a grant from MathWorks, Inc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
